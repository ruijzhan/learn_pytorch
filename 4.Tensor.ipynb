{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Tensor 基础\n",
    "\n",
    "张量(Tensor)是深度学习领域中最基本和重要的概念。张量可以简单地理解为多维数组，它们可以表示各种数据，如图片、声音、文本、序列等等。\n",
    "\n",
    "简单来说,张量是一种多维的数组。它包含了三个组成部分:\n",
    "\n",
    "1. 顺序:张量中的元素是按照特定顺序排列的。\n",
    "\n",
    "2. 维度:张量有一个或多个维度,也称为秩(Rank)。一维张量表示向量,二维张量表示矩阵,三维张量表示三维数据等。\n",
    "\n",
    "3. 元素类型:张量中的元素可以是整数、浮点数或其他类型。常见类型有 torch.float32、torch.float64、torch.uint8 和 torch.int64 \n",
    "\n",
    "张量在深度学习领域中有几个主要用途:\n",
    "\n",
    "1. 作为输入:许多深度学习模型的输入都是多维数据,可以使用张量作为输入。\n",
    "\n",
    "2. 作为参数:模型中的各种参数,如卷积核、 fully connected 层的权重矩阵等,都是使用张量表示。 \n",
    "\n",
    "3. 作为输出:模型的输出也通常是多维的,可以使用张量表示。\n",
    "\n",
    "4. 操作:张量提供了丰富的操作接口,包括张量间的数学运算、变换等。这是深度学习模型能完成复杂计算的基础。\n",
    "\n",
    "## 1 Tensor 的创建\n",
    "\n",
    "### 1.1 使用 torch.tensor()\n",
    "\n",
    "torch.tensor() 是一个构造函数，可以从给定的 Python 列表、NumPy 数组等 Python 可迭代对象中构建张量，并且可以指定数据类型（dtype）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([1., 2., 3.])\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1354787/2276574261.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(x, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 从 Python 列表创建\n",
    "x = torch.tensor([1, 2, 3])\n",
    "print(x)  # 输出：tensor([1, 2, 3])\n",
    "\n",
    "# 从 NumPy 数组 创建，同时设置 dtype\n",
    "arr = np.array([[1, 2, 3], [4,5, 6]], dtype=np.int64)\n",
    "x = torch.tensor(arr)\n",
    "print(x)  # 输出：tensor([[1, 2, 3],\n",
    "          #         [4, 5, 6]], dtype=torch.int64)\n",
    "\n",
    "# 或者使用 from_numpy 函数\n",
    "x = torch.from_numpy(arr)\n",
    "print(x) \n",
    "\n",
    "# 从张量创建\n",
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor(x, dtype=torch.float32)\n",
    "print(y)  # 输出：tensor([1., 2., 3.])\n",
    "\n",
    "# 指定是否需要计算梯度\n",
    "x = torch.tensor([1, 2, 3], dtype=torch.float32, requires_grad=True)\n",
    "print(x.requires_grad)  # 输出：True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把 requires_grad 设置成 true 或者 false 要灵活处理。如果是训练过程就要设置为 true，目的是方便求导、更新参数。而到了验证或者测试过程，我们的目的是检查当前模型的泛化能力，那就要把 requires_grad 设置成 Fasle，避免这个参数根据 loss 自动更新。\n",
    "\n",
    "### 1.2 全零，全一，单位 Tensor 的创建\n",
    "\n",
    "#### 1.2.1 全零张量\n",
    "\n",
    "`torch.zeros()` 是一个在 PyTorch 中创建零矩阵的函数。返回一个包含全零元素的张量（tensor），其形状由传入的参数确定。`torch.zeros()` 函数的语法如下：\n",
    "\n",
    "```python\n",
    "torch.zeros(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
    "```\n",
    "\n",
    "参数说明：\n",
    "\n",
    "- `*size`：表示张量的形状（shape），可以是一个整数序列，如 `(2, 3)` 表示一个 2x3 的矩阵。\n",
    "- `out`（可选）：指定输出张量。默认为 `None`。\n",
    "- `dtype`（可选）：指定张量的数据类型。默认为 `None`，表示使用全局默认数据类型。\n",
    "- `layout`（可选）：指定张量的内存布局。默认为 `torch.strided`。\n",
    "- `device`（可选）：指定张量存储的设备（CPU 或 GPU）。默认为 `None`，表示使用全局默认设备。\n",
    "- `requires_grad`（可选）：指定是否需要计算梯度。默认为 `False`。\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]], dtype=torch.int32)\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "zeros_3_3 = torch.zeros(3, 3)\n",
    "print(zeros_3_3)\n",
    "\n",
    "# 指定类型\n",
    "zeros_int = torch.zeros(3, 3, dtype=torch.int)\n",
    "print(zeros_int)\n",
    "\n",
    "# 指定设备\n",
    "zeros_dev = torch.zeros(3,3,device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "print(zeros_dev)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 全一张量\n",
    "\n",
    "`torch.ones()` 是一个在 PyTorch 中创建全一矩阵的函数。它返回一个包含全一元素的张量（tensor），其形状由传入的参数确定。`torch.ones()` 函数的语法如下：\n",
    "\n",
    "```python\n",
    "torch.ones(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
    "```\n",
    "\n",
    "参数跟 torch.zeros() 类似。\n",
    "\n",
    "#### 单位张量\n",
    "\n",
    "`torch.eye()` 是一个在 PyTorch 中创建单位矩阵（identity matrix）的函数。它返回一个包含对角线元素为 1，其余元素为 0 的方阵（square matrix）。`torch.eye()` 函数的语法如下：\n",
    "\n",
    "```python\n",
    "torch.eye(n, m=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "identity_matrix = torch.eye(3)\n",
    "print(identity_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单位矩阵具有以下性质：\n",
    "\n",
    "1. **乘法恒等**：单位矩阵与任意矩阵相乘，结果仍为原矩阵。对于任意矩阵 A，都有 `AI = IA = A`，其中 I 为单位矩阵。\n",
    "\n",
    "在深度学习和 PyTorch 中，单位矩阵主要用于以下场景：\n",
    "\n",
    "1. **矩阵初始化**：在某些深度学习模型中，权重矩阵的初始化策略可能选择单位矩阵。例如，在循环神经网络（RNN）中，人们可能会将权重矩阵初始化为单位矩阵，以减小梯度消失或梯度爆炸问题。\n",
    "\n",
    "2. **线性变换保持不变**：单位矩阵可以用于表示线性变换中的恒等映射。在深度学习中，我们经常使用线性变换对数据进行处理。当线性变换中的权重矩阵为单位矩阵时，表示输入数据在变换过程中保持不变。\n",
    "\n",
    "3. **矩阵求逆**：单位矩阵在计算矩阵求逆时具有重要作用。对于一个可逆的方阵 A，存在一个矩阵 B，使得 `AB = BA = I`，其中 I 为单位矩阵。在深度学习的某些优化算法（如牛顿法和拟牛顿法）中，需要计算矩阵的逆或伪逆。\n",
    "\n",
    "4. **恒等映射层**：在深度学习中，有时会使用恒等映射层（如 ResNet 中的跳跃连接）。这些层的作用是将输入直接传递到输出，而不进行任何变换。在这种情况下，可以将这些层的权重表示为单位矩阵。\n",
    "\n",
    "### 1.3 随机矩阵张量\n",
    "\n",
    "在深度学习与 PyTorch 中，随机矩阵张量是一种特殊的张量，其元素根据特定的概率分布（如均匀分布、正态分布等）随机生成。随机矩阵张量在深度学习中具有广泛的应用，如权重初始化、数据增强、抽样等。\n",
    "\n",
    "PyTorch 提供了多种用于生成随机矩阵张量的方法：\n",
    "\n",
    "#### 1.3.1 `torch.rand()`：生成一个包含在 `[0, 1)` 之间均匀分布的随机数的矩阵张量\n",
    "\n",
    "场景：当需要创建包含 [0, 1) 区间内的均匀分布随机数的矩阵张量时，可以使用此方法。这对于一些初始化策略或随机采样任务可能很有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2157, 0.5359, 0.2594],\n",
      "        [0.8642, 0.4641, 0.5004],\n",
      "        [0.8087, 0.1403, 0.1911]])\n"
     ]
    }
   ],
   "source": [
    "random_matrix = torch.rand(3, 3)\n",
    "print(random_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 1.3.2 `torch.randn()`：生成一个包含标准正态分布（均值为 0，标准差为 1）随机数的矩阵张量\n",
    "\n",
    "**均值 (mean)** : 是数据集中所有数值的平均值。它衡量了数据集中心位置的一种指标。计算均值的方法是将所有数值相加，然后除以数据集中数据点的数量:\n",
    "\n",
    "```\n",
    "mean = (x1 + x2 + ... + xn) / n\n",
    "```\n",
    "\n",
    "**标准差（standard deviation）**：标准差是衡量数据集离散程度的一种指标，它表示数据点与均值之间的平均偏差。较大的标准差意味着数据点更分散，较小的标准差意味着数据点更集中。计算标准差的方法是先计算每个数据点与均值的差的平方，然后计算这些平方差的平均值，最后取平方根\n",
    "\n",
    "```\n",
    "standard_deviation = sqrt(((x1 - mean)^2 + (x2 - mean)^2 + ... + (xn - mean)^2) / n)\n",
    "```\n",
    "\n",
    "场景：当需要创建符合标准正态分布的随机数矩阵张量时，可以使用此方法。这在初始化神经网络权重时非常常见，因为标准正态分布有助于更好地保持梯度在网络中的传播。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0530, -0.6079,  0.4859],\n",
      "        [-0.8292,  0.1639,  1.2059],\n",
      "        [ 1.2127,  0.1083,  0.4566]])\n"
     ]
    }
   ],
   "source": [
    "random_matrix = torch.randn(3, 3)\n",
    "print(random_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3  `torch.randint()`：生成一个包含在给定区间内的整数随机数的矩阵张量\n",
    "\n",
    "场景：当需要创建包含特定整数范围内的随机数矩阵张量时，可以使用此方法。这在随机采样、生成伪标签或选择随机索引时非常有用。\n",
    "\n",
    "```python\n",
    "torch.randint(low: int, high: int, size: Tuple[int, ...], *, generator=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
    "```\n",
    "\n",
    "参数说明：\n",
    "\n",
    "- `low`：生成随机整数的下界（包含）。\n",
    "- `high`：生成随机整数的上界（不包含）。\n",
    "- `size`：生成的矩阵张量的形状，表示为一个包含整数的元组。\n",
    "- 其他可选参数，如 `generator`、`out`、`dtype`、`layout`、`device` 和 `requires_grad`，用于指定生成的矩阵张量的属性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8, 2, 3],\n",
      "        [0, 9, 1],\n",
      "        [9, 5, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 生成一个包含随机整数的 3x3 矩阵张量，整数范围为 [0, 10)\n",
    "random_matrix = torch.randint(low=0, high=10, size=(3, 3))\n",
    "print(random_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.4 `torch.normal()` 生成一个具有指定均值和标准差的正态分布随机数的矩阵张量\n",
    "\n",
    "在深度学习场景和 PyTorch 中，这种随机矩阵张量有多种应用，如权重初始化、噪声注入和随机变量采样等。\n",
    "\n",
    "```python\n",
    "torch.normal(mean, std, *, generator=None, out=None)\n",
    "```\n",
    "\n",
    "参数说明：\n",
    "\n",
    "- `mean`：生成正态分布随机数的均值，可以是一个标量或一个与输出张量形状相同的张量。\n",
    "- `std`：生成正态分布随机数的标准差，可以是一个标量或一个与输出张量形状相同的张量。\n",
    "- 其他可选参数，如 `generator` 和 `out`，用于指定生成的矩阵张量的属性。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9.9056e-01,  1.2980e+00, -2.2368e-01],\n",
      "        [-1.5112e-01, -1.6309e-01,  3.1360e-01],\n",
      "        [ 3.6322e-01,  7.6014e-01, -8.8695e-04]])\n"
     ]
    }
   ],
   "source": [
    "# 生成一个具有指定均值和标准差的 3x3 正态分布随机数矩阵。效果与上面的 randn 一样\n",
    "mean = 0.0\n",
    "std = 1.0\n",
    "random_matrix = torch.normal(mean, std, size=(3, 3))\n",
    "print(random_matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.5 `torch.randperm()`：生成一个包含给定范围内随机排列整数的一维张量\n",
    "\n",
    "它会生成一个长度为 n 的整数序列，其中每个整数都在 0 到 n-1 之间，且每个整数只出现一次。\n",
    "\n",
    "```python\n",
    "torch.randperm(n, *, generator=None, out=None, device=None, dtype=None) -> Tensor\n",
    "```\n",
    "\n",
    "场景：当需要创建一个乱序的整数排列时，可以使用此方法。这在数据集的随机分割、洗牌操作或生成随机索引时非常有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 7, 2, 6, 8, 0, 3, 9, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "random_permutation = torch.randperm(10)\n",
    "print(random_permutation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Tensor 的转换\n",
    "\n",
    "为了实现与其他库的兼容性、方便数据输入输出、提高代码灵活性和可读性、优化内存使用和计算速度，以及适应神经网络中不同操作之间的数据传递需求，需要对 Tensor 在不同数据结构之间做转换。\n",
    "\n",
    "### 2.1 int 与 Tensor 之间的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(42)\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "x = 42\n",
    "tensor_x = torch.tensor(x)\n",
    "print(tensor_x)  # 输出：tensor(42)\n",
    "\n",
    "tensor_x = torch.tensor(42)\n",
    "x = tensor_x.item()\n",
    "print(x)  # 输出：42"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 list 与 Tensor 之间的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5])\n",
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "x = [1, 2, 3, 4, 5]\n",
    "tensor_x = torch.tensor(x)\n",
    "print(tensor_x)  # 输出：tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "tensor_x = torch.tensor([1, 2, 3, 4, 5])\n",
    "x = tensor_x.tolist()\n",
    "print(x)  # 输出：[1, 2, 3, 4, 5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 NumPy 与 Tensor 之间的转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5])\n",
      "[1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4, 5])\n",
    "tensor_x = torch.from_numpy(x)\n",
    "print(tensor_x)  # 输出：tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "tensor_x = torch.tensor([1, 2, 3, 4, 5])\n",
    "x = tensor_x.numpy()\n",
    "print(x)  # 输出：array([1, 2, 3, 4, 5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Tensor 的常见操作\n",
    "\n",
    "### 3.1 获取形状\n",
    "\n",
    "了解 Tensor 的形状和尺寸的意义至关重要，原因如下：\n",
    "\n",
    "1. **数据表示**：Tensor 的形状和尺寸描述了数据在多维空间中的布局。例如，在计算机视觉任务中，一个形状为 (3, 224, 224) 的 Tensor 可以表示一张 224x224 像素的彩色图像，其中 3 个通道分别对应 RGB 三种颜色。了解 Tensor 的形状和尺寸有助于我们理解数据的结构。\n",
    "\n",
    "2. **操作兼容性**：在神经网络中，许多操作要求输入具有特定的形状。例如，矩阵乘法要求第一个矩阵的列数等于第二个矩阵的行数。为了确保操作可以正确执行，我们需要知道 Tensor 的形状和尺寸。\n",
    "\n",
    "3. **网络设计**：在设计深度学习模型时，我们需要了解每一层输出的形状和尺寸以便正确地连接各个层。例如，在卷积神经网络 (CNN) 的设计中，了解输入数据的形状有助于我们选择合适的过滤器大小、步长和填充。类似地，在循环神经网络 (RNN) 中，了解输入序列的长度和维数对于设置正确的隐藏层尺寸和循环次数非常重要。\n",
    "\n",
    "4. **资源需求**：了解 Tensor 的形状和尺寸有助于我们估计模型的内存和计算需求。对于大型模型和数据集，了解 Tensor 的尺寸可以帮助我们优化模型结构和计算资源以提高训练和推理速度。\n",
    "\n",
    "在 PyTorch 中，可以使用以下方法获取 Tensor 的形状和尺寸：\n",
    "\n",
    "1. **`shape` 属性**：使用 `shape` 属性可以直接获取 Tensor 的形状。它会返回一个表示各个维度大小的元组。\n",
    "\n",
    "2. **`size()` 方法**：使用 `size()` 方法也可以获取 Tensor 的形状。它的返回值与 `shape` 属性相同。\n",
    "\n",
    "3. **`dim()` 方法**：使用 `dim()` 方法可以获取 Tensor 的维数，即 Tensor 的秩。例如，在二维矩阵中，`dim()` 返回值为 2。\n",
    "\n",
    "4. **`numel()` 方法**: 使用 `numel()` 方法获取 Tensor 中元素的个数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "2\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "tensor_x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(tensor_x.shape)  # 输出：torch.Size([2, 3])\n",
    "\n",
    "print(tensor_x.size())  # 输出：torch.Size([2, 3])\n",
    "\n",
    "print(tensor_x.dim())  # 输出：2\n",
    "\n",
    "print(tensor_x.numel()) # 输出：6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 维度的变换\n",
    "\n",
    "#### 3.2.1 permute(): 重新排列 Tensor 的轴\n",
    "\n",
    "permute() 函数可以用于多维 Tensor 的任意轴置换。\n",
    "\n",
    "```python\n",
    "def permute(self, *dims: int) -> 'Tensor':\n",
    "    ...\n",
    "```\n",
    "在调用 permute() 函数时，将新的轴顺序作为参数传递。例如，要交换一个 Tensor 的第 0 轴和第 1 轴，可以调用 tensor.permute(1, 0)。\n",
    "\n",
    "注意，对张量使用 permute() 后，会使其元素在内存中的排列变得不连续，如果此时对张量调用 view() 变换形状时，会报错。此时需调用 reshape()。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始 Tensor 形状： torch.Size([2, 3, 4])\n",
      "调整轴顺序后的 Tensor 形状： torch.Size([3, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个形状为 (2, 3, 4) 的三维 Tensor\n",
    "tensor_x = torch.randn(2, 3, 4)\n",
    "print(\"原始 Tensor 形状：\", tensor_x.shape)  # 输出：torch.Size([2, 3, 4])\n",
    "\n",
    "# 使用 permute() 交换轴顺序\n",
    "tensor_y = tensor_x.permute(1, 2, 0)\n",
    "print(\"调整轴顺序后的 Tensor 形状：\", tensor_y.shape)  # 输出：torch.Size([3, 4, 2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 transpose(): 用于交换 Tensor 的两个轴\n",
    "\n",
    "transpose() 函数在需要交换两个轴的情况下更简单易用。\n",
    "\n",
    "```python\n",
    "def transpose(self, dim0: int, dim1: int) -> 'Tensor':\n",
    "    ...\n",
    "```\n",
    "\n",
    "在调用 transpose() 函数时，将要交换的轴的索引作为参数传递。例如，要交换一个 Tensor 的第 0 轴和第 1 轴，可以调用 tensor.transpose(0, 1)。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始 Tensor：\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "转置后的 Tensor：\n",
      " tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "# 将原始 Tensor 的第 0 轴和第 1 轴进行交换，实现了矩阵的转置\n",
    "\n",
    "# 创建一个形状为 (2, 3) 的二维 Tensor\n",
    "tensor_x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"原始 Tensor：\\n\", tensor_x)\n",
    "# 输出：\n",
    "# tensor([[1, 2, 3],\n",
    "#         [4, 5, 6]])\n",
    "\n",
    "# 使用 transpose() 交换轴顺序\n",
    "tensor_y = tensor_x.transpose(0, 1)\n",
    "print(\"转置后的 Tensor：\\n\", tensor_y)\n",
    "# 输出：\n",
    "# tensor([[1, 4],\n",
    "#         [2, 5],\n",
    "#         [3, 6]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 形状的变换\n",
    "\n",
    "#### 3.3.1 view()\n",
    "\n",
    "`view()`方法接受一个或多个整数作为参数，用于指定目标张量的形状。它返回一个具有指定形状的新张量，该张量与原始张量共享内存。因此，对其中一个张量的修改会影响另一个张量。\n",
    "\n",
    "原始张量和目标张量的元素个数必须相同。否则，`view()`方法会抛出异常。`view()`方法要求原始张量的内存布局是连续的。如果不满足这个条件，需要先调用`contiguous()`方法。或者直接用 `reshape()` 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4, 2],\n",
      "        [5, 3, 6]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个形状为(2, 3)的Tensor\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# 交换 x 的两个轴，此时 x 的形状变为 3,2，元素在内存中变得不连续\n",
    "x = x.permute(1, 0)\n",
    "\n",
    "x = x.contiguous()\n",
    "\n",
    "# 使用view()方法变换形状为(2, 3)\n",
    "x_view = x.view(2, 3)\n",
    "print(x_view)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4,  5,  6],\n",
      "        [ 7,  8,  9, 10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 创建一个形状为(2, 2, 3)的Tensor\n",
    "x = torch.tensor([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "\n",
    "# 使用view()方法变换形状为(2, 6)\n",
    "x_view = x.view(2, -1)  # 使用-1表示该维度根据其他维度自动计算\n",
    "print(x_view)\n",
    "# 结果：\n",
    "# tensor([[ 1,  2,  3,  4,  5,  6],\n",
    "#         [ 7,  8,  9, 10, 11, 12]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在使用`view()`方法时，需要注意以下几点：\n",
    "\n",
    "- 确保原始张量和目标张量的元素个数相同。\n",
    "- 如果原始张量的内存布局不连续，先调用`contiguous()`方法。\n",
    "- 如果不确定某一维度的大小，可以使用-1让PyTorch自动计算。\n",
    "- 要确保张量形状的变化是符合预期的，避免因为错误的张量形状导致计算错误。\n",
    "\n",
    "#### 3.3.2 reshape()\n",
    "\n",
    "`reshape()` 方法接受一个或多个整数作为参数，用于指定目标张量的形状。它返回一个具有指定形状的新张量，该张量可能与原始张量共享内存，也可能不共享。因此，在某些情况下，对其中一个张量的修改可能不会影响另一个张量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4,  5,  6],\n",
      "        [ 7,  8,  9, 10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个形状为(2, 3)的Tensor\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# 使用reshape()方法变换形状为(3, 2)\n",
    "x_reshape = x.reshape(3, 2)\n",
    "\n",
    "# 结果：\n",
    "# tensor([[1, 2],\n",
    "#         [3, 4],\n",
    "#         [5, 6]])\n",
    "\n",
    "# 创建一个形状为(2, 2, 3)的Tensor\n",
    "x = torch.tensor([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "\n",
    "# 使用reshape()方法变换形状为(2, 6)\n",
    "x_reshape = x.reshape(2, -1)  # 使用-1表示该维度根据其他维度自动计算\n",
    "print(x_reshape)\n",
    "# 结果：\n",
    "# tensor([[ 1,  2,  3,  4,  5,  6],\n",
    "#         [ 7,  8,  9, 10, 11, 12]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在使用`reshape()`方法时，需要注意以下几点：\n",
    "\n",
    "- 确保原始张量和目标张量的元素个数相同。\n",
    "- 如果不确定某一维度的大小，可以使用-1让PyTorch自动计算。\n",
    "- 要确保张量形状的变化是符合预期的，避免因为错误的张量形状导致计算错误。\n",
    "- 注意`reshape()`方法可能导致额外的内存分配和复制开销。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 3.4 维度的增减\n",
    "\n",
    "#### 3.4.1 增加维度\n",
    "\n",
    "增加维度通常用于在数据和模型之间插入一个新的轴。例如，将输入数据扩展为批量数据，或将单通道图像扩展为多通道图像。\n",
    "\n",
    "可以使用unsqueeze()方法或None索引（即np.newaxis）来增加维度。同时确保在正确的轴上增加维度，以免引入错误的计算。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8],\n",
      "         [ 9, 10, 11, 12]]])\n",
      "tensor([[[ 1,  2,  3,  4]],\n",
      "\n",
      "        [[ 5,  6,  7,  8]],\n",
      "\n",
      "        [[ 9, 10, 11, 12]]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个形状为(3, 4)的Tensor\n",
    "x = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
    "\n",
    "# 使用unsqueeze()方法在第0轴增加维度\n",
    "x_unsqueeze = x.unsqueeze(0)\n",
    "print(x_unsqueeze)\n",
    "\n",
    "# 结果：形状为(1, 3, 4)的Tensor\n",
    "# tensor([[[ 1,  2,  3,  4],\n",
    "#          [ 5,  6,  7,  8],\n",
    "#          [ 9, 10, 11, 12]]])\n",
    "\n",
    "# 使用None索引在第1轴增加维度\n",
    "x_newaxis = x[:, None, :]\n",
    "print(x_newaxis)\n",
    "\n",
    "# 结果：形状为(3, 1, 4)的Tensor\n",
    "# tensor([[[ 1,  2,  3,  4]],\n",
    "#\n",
    "#         [[ 5,  6,  7,  8]],\n",
    "#\n",
    "#         [[ 9, 10, 11, 12]]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 删除维度\n",
    "\n",
    "可以使用squeeze()方法删除维度。确保只删除不必要的维度，以免影响计算的正确性。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n"
     ]
    }
   ],
   "source": [
    "# 创建一个形状为(1, 3, 4)的Tensor\n",
    "x = torch.tensor([[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]])\n",
    "\n",
    "# 使用squeeze()方法删除第0轴\n",
    "x_squeeze = x.squeeze(0)\n",
    "\n",
    "print(x_squeeze)\n",
    "\n",
    "# 结果：形状为(3, 4)的Tensor\n",
    "# tensor([[ 1,  2,  3,  4],\n",
    "#         [ 5,  6,  7,  8],\n",
    "#         [ 9, 10, 11, 12]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
